#!/usr/local/bin/python3
import asyncio
import grpc
import rpc_pb2
import rpc_pb2_grpc
from aiohttp import web
import logging
import sys

log = []

# how to specify timout on request?
# Plus I need multiple connections to multiple secondaries

# GRPC clients
# For more channel options, please see https://grpc.io/grpc/core/group__grpc__arg__keys.html
CHANNEL_OPTIONS = [
    # ('grpc.lb_policy_name', 'pick_first'),
    # ('grpc.enable_retries', 0),
    ('grpc.keepalive_timeout_ms', 5000)
]
secondaries_dns_names = [
    f'dist_systems.s.{i+1}' for i in range(0, int(sys.argv[1]))
]
MAX_WRITE_CONCERN = 1 + len(secondaries_dns_names)

async def replicate_msg(sec_ip, msg):
    # this will recreate channel on every single request, is it OK ?
    # need to understand what is this channel
    async with grpc.aio.insecure_channel(target=f'{sec_ip}:{50051}',
                                         options=CHANNEL_OPTIONS) as channel:
        stub = rpc_pb2_grpc.ReplicatorStub(channel)
        # response = await stub.replicateMsg(rpc_pb2.Request(msg=msg),
        #                                timeout=10)
        logging.info('Waiting for gRPC response from %s', sec_ip)
        response = await stub.replicateMsg(rpc_pb2.Request(msg=msg))
    logging.info('%s on %s', 'ACK' if response.success else 'Fail', sec_ip)
    return (sec_ip, response.success)

# HTTP server
# https://demos.aiohttp.org/en/latest/tutorial.html#aiohttp-demos-polls-getting-started
async def handle_list(request):
    return web.Response(text='\n'.join(log) + '\n')

async def handle_append(request):
    logging.info('Processing http request from %r', request.remote)
    body = await request.json()
    
    msg = body.get('msg')
    if msg is None:
        logging.error('Wrong POST body %s\n', body)
        return web.Response(text=f'Failed to parse POST request: Wrong POST body. Request should have "msg" and optionally "w"(write concern) keys\n', status=400)
    
    write_concern = int(body.get('w', MAX_WRITE_CONCERN))
    if write_concern < 1 or write_concern > MAX_WRITE_CONCERN:
        logging.error('Wrong write_concern parameter %s\n', body)
        return web.Response(text=f'Failed to parse POST request: Wrong write_concern parameter. write_concern shouldn\'t be greater than {MAX_WRITE_CONCERN}\n', status=400)

    num_of_acks_to_wait_for = write_concern - 1
    logging.info(f'Waiting for ACKs from {num_of_acks_to_wait_for} secondary/-ies')
    if num_of_acks_to_wait_for == 0:
        log.append(msg)
        logging.info(f'Appended {msg} to in-memory list\n')
        return web.Response(text=f'Appended {msg} to in-memory list\n')

    secondaries_not_to_await_acks = secondaries_dns_names[num_of_acks_to_wait_for:]
    for s in secondaries_not_to_await_acks:
        # will it swear about me not awaiting for them?
        asyncio.get_event_loop().create_task(replicate_msg(s, msg))

    secondaries_to_await_acks = secondaries_dns_names[:num_of_acks_to_wait_for]
    acks_info = await asyncio.gather(*[replicate_msg(s, msg) for s in secondaries_to_await_acks])

    logging.info(f'ACKs: {acks_info}')
    if all([ack[1] for ack in acks_info]):
        log.append(msg)
        logging.info(f'Appended {msg} to in-memory list\n')
        return web.Response(text=f'Appended {msg} to in-memory list\n')
    else:
        # here some secondaries could have added msg, but some didn't. And master didn't.
        logging.error(f'Failed to append {msg}: Got not enough ACKs from secondaries\n')
        return web.Response(text=f'Failed to append "{msg}": Got not enough ACKs from secondaries\n', status=500)

if (len(sys.argv) < 2):
    print('Usage: master <number_of_secondaries>')
    exit(1)

app = web.Application()
app.add_routes([web.get('/list', handle_list),
                web.post('/append', handle_append)])
logging.basicConfig(
    level=logging.DEBUG,
    format='[%(asctime)s.%(msecs)03d] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s',
    datefmt='%H:%M:%S',
    stream=sys.stdout)
web.run_app(app, access_log=None)
